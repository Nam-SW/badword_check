{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bad_word_check.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5EWr4Hmf+0VvuIxFRXKSE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nam-SW/badword_check/blob/master/bad_word_check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EyZLR0K6AiU",
        "colab_type": "text"
      },
      "source": [
        "# 딥러닝을 통한 욕설 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN_Sl72e6EaX",
        "colab_type": "text"
      },
      "source": [
        "구글 드라이브 연결. 깃허브에 올라가 있는 `badword.xlsx` 와 `goodword.xlsx`를 드라이브에 올리시고, 아래 `base_url` 변수를 수정해주시면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5C4DVbLEKo7",
        "colab_type": "code",
        "outputId": "315e82c4-5710-4f35-bd0a-502349644998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "base_url = '/content/gdrive/My Drive/project/badword/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V2CUPIE6cY-",
        "colab_type": "text"
      },
      "source": [
        "채팅을 자모단위로 분리할 hgtk 라이브러리를 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu7QvgvSKYCq",
        "colab_type": "code",
        "outputId": "6a970d42-197c-4898-dd6f-6d1dab6c02c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "!pip install hgtk"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hgtk\n",
            "  Downloading https://files.pythonhosted.org/packages/79/04/04758ed8c086fb1d9a5a267f90239533d33dbc1646ac32f8bf80e38b0ec7/hgtk-0.1.3.tar.gz\n",
            "Building wheels for collected packages: hgtk\n",
            "  Building wheel for hgtk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hgtk: filename=hgtk-0.1.3-py2.py3-none-any.whl size=6689 sha256=d2e620d1dd334873d52e60578377669a58a26785254b67e6b2b4642eb3c9ad23\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/72/06/6065a57fe68264f35d7e52e37f56831eb3e9ec75656880de20\n",
            "Successfully built hgtk\n",
            "Installing collected packages: hgtk\n",
            "Successfully installed hgtk-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBVAMoRM6ff3",
        "colab_type": "text"
      },
      "source": [
        "텐서보드를 이용해 학습을 시각적으로 확인합니다.  \n",
        "아래 코드를 실행시키고 학습을 진행시킨 후, 1 에포크 이후에 링크를 클릭해 들어가시면 정상적으로 작동합니다.  \n",
        "다시 학습시켜서 이를 텐서보드로 확인하고싶으시다면 런타임 초기화를 해서 다시 실행해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR_DOXd6aPn3",
        "colab_type": "code",
        "outputId": "f4704edc-7c0a-4e0f-bfe5-6e282d06a2c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "LOG_DIR = 'drive/data/tb_logs'\n",
        "\t\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "import os\n",
        "if not os.path.exists(LOG_DIR):\n",
        "    os.makedirs(LOG_DIR)\n",
        "else:\n",
        "    os.rmdir(LOG_DIR)\n",
        "    os.makedirs(LOG_DIR)\n",
        "  \n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR))\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-25 08:41:09--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.192.111.148, 3.229.196.117, 54.158.230.58, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.192.111.148|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  13%[=>                  ]   1.75M  8.71MB/s               \rngrok-stable-linux- 100%[===================>]  13.13M  37.8MB/s    in 0.3s    \n",
            "\n",
            "2020-03-25 08:41:10 (37.8 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "https://4551cce0.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm8Lg62k678m",
        "colab_type": "text"
      },
      "source": [
        "채팅내용을 인코딩하는 함수입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIY7r9UyKOaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "from hgtk.text import compose, decompose\n",
        "from string import ascii_lowercase, ascii_uppercase\n",
        "\n",
        "\n",
        "jaem = ['ㄱ', 'ㄴ', 'ㄷ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅅ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ', 'ㄲ', 'ㄸ', 'ㅃ', 'ㅆ', 'ㅉ', 'ㄳ', 'ㄵ', 'ㄶ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅄ']\n",
        "moem = ['ㅏ', 'ㅑ', 'ㅓ', 'ㅕ', 'ㅗ', 'ㅛ', 'ㅜ', 'ㅠ', 'ㅡ', 'ㅣ', 'ㅐ', 'ㅒ', 'ㅔ', 'ㅖ', 'ㅘ', 'ㅙ', 'ㅚ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅢ']\n",
        "english = list(ascii_lowercase) + list(ascii_uppercase)\n",
        "sign = [s for s in ''' `~!@#$%^&*()+-/=_,.?;:'\"[]{}<>\\|''']\n",
        "\n",
        "link_list = sign + jaem + moem + english + [str(i) for i in range(10)]\n",
        "voc_size = len(link_list) + 1 # OOV 포함!\n",
        "encoding_dict = defaultdict(lambda : 0, {k:code+1 for code, k in enumerate(link_list)}) # 0은 OOV\n",
        "\n",
        "\n",
        "def encode(text):\n",
        "    text = decompose(text).replace('ᴥ', '')\n",
        "    code = [encoding_dict[t] for t in text]\n",
        "    return code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3utkqkq7AWx",
        "colab_type": "text"
      },
      "source": [
        "구글 드라이브에서 데이터를 불러와 인코딩 후 저장하는 데이터 클래스를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TelzuAUIKd0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Data:\n",
        "    def __init__(self, maxlen):\n",
        "        bad = pd.read_excel(base_url + 'badword.xlsx', encoding='utf-8-sig')\n",
        "        bad.dropna(how='any', inplace=True)\n",
        "        good = pd.read_excel(base_url + 'goodword.xlsx', encoding='utf-8-sig')\n",
        "        good.dropna(how='any', inplace=True)\n",
        "\n",
        "        bad_len = len(bad)\n",
        "        good_len = len(good)\n",
        "\n",
        "        if bad_len > good_len:\n",
        "            good = good[:bad_len]\n",
        "        else:\n",
        "            bad = bad[:good_len]\n",
        "        df = pd.concat([bad, good])\n",
        "\n",
        "        X = df['data'].to_list()\n",
        "        Y = df['label'].to_numpy()\n",
        "\n",
        "        for i in range(len(X)):\n",
        "            d = X[i]\n",
        "            encoding = encode(d)\n",
        "            if len(encoding) > maxlen:\n",
        "                nplist = np.array(encoding[:maxlen])\n",
        "            else:\n",
        "                # nplist = np.zeros(maxlen)\n",
        "                # for i in range()\n",
        "                encoding = [0] * (maxlen - len(encoding)) + encoding\n",
        "                nplist = np.array(encoding)\n",
        "\n",
        "            X[i] = nplist\n",
        "        \n",
        "        X = np.array(X)\n",
        "        # Y = df['label'].to_numpy()\n",
        "        datalen = X.shape[0]\n",
        "\n",
        "        s = np.arange(datalen)\n",
        "        np.random.shuffle(s)\n",
        "        X, Y = X[s], Y[s]\n",
        "\n",
        "        slicelen = int(datalen * 0.9)\n",
        "        x_train = X[:slicelen]\n",
        "        y_train = Y[:slicelen]\n",
        "\n",
        "        x_test = X[slicelen:]\n",
        "        y_test = Y[slicelen:]\n",
        "\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "        self.x_test = x_test\n",
        "        self.y_test = y_test\n",
        "        self.input_shape = x_train.shape[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5podorVl7Hg-",
        "colab_type": "text"
      },
      "source": [
        "모델을 빌드하는 함수를 만듭니다.  \n",
        "여러번 돌려본 결과 Conv1D 블럭 하나만 하는게 가장 성능이 뛰어났습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiYUO1kMr-ux",
        "colab_type": "code",
        "outputId": "a3b05a3b-bddc-4d2a-8420-41d977bcb666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "from keras import layers\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "def build_model(input_shape):\n",
        "    input_layer = layers.Input(input_shape, name='input_layer')\n",
        "\n",
        "    embedding = layers.Embedding(voc_size, 64)(input_layer)\n",
        "    residual1 = layers.Conv1D(64, 10, name='block1_residual')(embedding)\n",
        "    x1 = layers.Conv1D(64, 10, padding='same', activation='relu', name='block1_Conv1')(residual1)\n",
        "    # x1 = layers.Dropout(0.2, name='block1_Dropout')(x1)\n",
        "    x1 = layers.Conv1D(64, 10, padding='same', activation='relu', name='block1_Conv2')(x1)\n",
        "    x1 = layers.add([residual1, x1], name='block1_add')\n",
        "    x1 = layers.MaxPool1D(2, name='block1_MaxPool')(x1)\n",
        "\n",
        "    # residual2 = layers.Conv1D(32, 10, name='block2_residual')(x1)\n",
        "    # x2 = layers.Conv1D(32, 10, padding='same', activation='relu', name='block2_Conv1')(residual2)\n",
        "    # # x2 = layers.Dropout(0.2, name='block2_Dropout')(x2)\n",
        "    # x2 = layers.Conv1D(32, 10, padding='same', activation='relu', name='block2_Conv2')(x2)\n",
        "    # x2 = layers.add([residual2, x2], name='block2_add')\n",
        "    # x2 = layers.MaxPool1D(2, name='block2_MaxPool')(x2)\n",
        "    \n",
        "    # residual3 = layers.Conv1D(32, 10, name='block3_residual')(x2)\n",
        "    # x3 = layers.Conv1D(32, 10, padding='same', activation='relu', name='block3_Conv1')(residual3)\n",
        "    # # x3 = layers.Dropout(0.2, name='block3_Dropout')(x3)\n",
        "    # x3 = layers.Conv1D(32, 10, padding='same', activation='relu', name='block3_Conv2')(x3)\n",
        "    # x3 = layers.add([residual3, x3], name='block3_add')\n",
        "    # x3 = layers.MaxPool1D(2, name='block3_MaxPool')(x3)\n",
        "    \n",
        "    # lstm = layers.Bidirectional(layers.LSTM(32, dropout=0.1, recurrent_dropout=0.1, name='lstm'))(x3)\n",
        "    # lstm = layers.Bidirectional(layers.LSTM(32, dropout=0.1, recurrent_dropout=0.1, name='lstm'))(x2)\n",
        "    lstm = layers.Bidirectional(layers.LSTM(32, dropout=0.1, recurrent_dropout=0.1, name='lstm'))(x1)\n",
        "\n",
        "    output_layer = layers.Dense(1, activation='sigmoid', name='output_layer')(lstm)\n",
        "\n",
        "    m = Model(input_layer, output_layer)\n",
        "\n",
        "    m.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return m"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR1tHTk47SGg",
        "colab_type": "text"
      },
      "source": [
        "데이터의 최대 길이를 정의하고, 데이터 클래스와 모델을 빌드합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpPHjTdmpklz",
        "colab_type": "code",
        "outputId": "83f149fd-290e-4f8d-f05a-66923c62f834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        }
      },
      "source": [
        "maxlen = 100\n",
        "data = Data(maxlen)\n",
        "model = build_model(data.input_shape)\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_layer (InputLayer)        (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 100, 64)      9408        input_layer[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block1_residual (Conv1D)        (None, 91, 64)       41024       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block1_Conv1 (Conv1D)           (None, 91, 64)       41024       block1_residual[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_Conv2 (Conv1D)           (None, 91, 64)       41024       block1_Conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_add (Add)                (None, 91, 64)       0           block1_residual[0][0]            \n",
            "                                                                 block1_Conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_MaxPool (MaxPooling1D)   (None, 45, 64)       0           block1_add[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 64)           24832       block1_MaxPool[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "output_layer (Dense)            (None, 1)            65          bidirectional_1[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 157,377\n",
            "Trainable params: 157,377\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgb4xMiM7Zrw",
        "colab_type": "text"
      },
      "source": [
        "텐서보드, 학습 중지 등의 콜백 함수를 정의하고 학습을 시킵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaO-ImuSZp6t",
        "colab_type": "code",
        "outputId": "273ba737-2fff-4e87-e016-c314342a0892",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "from keras import callbacks\n",
        "\n",
        "\n",
        "callback_list = [\n",
        "                 callbacks.EarlyStopping(patience=3),\n",
        "                 callbacks.ModelCheckpoint(\n",
        "                     filepath=base_url + 'temp_model.h5',\n",
        "                     monitor='val_loss',\n",
        "                     save_best_only=True\n",
        "                 ),\n",
        "                 callbacks.ReduceLROnPlateau(\n",
        "                     monitor='val_loss',\n",
        "                     factor=0.1,\n",
        "                     patience=3\n",
        "                 ),\n",
        "                 callbacks.TensorBoard(log_dir=LOG_DIR,\n",
        "                             histogram_freq=1,\n",
        "                             embeddings_freq=1,\n",
        "                             embeddings_data=data.x_train[:300],\n",
        "                             write_graph=True,\n",
        "                             write_grads=True,\n",
        "                             write_images=True,\n",
        "                             )\n",
        "]\n",
        "\n",
        "history = model.fit(data.x_train,\n",
        "                    data.y_train,\n",
        "                    batch_size=5, \n",
        "                    epochs=4, \n",
        "                    validation_split=0.1, \n",
        "                    callbacks=callback_list\n",
        "                    )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 4671 samples, validate on 520 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1120: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1112: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1159: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "Epoch 1/4\n",
            "4671/4671 [==============================] - 73s 16ms/step - loss: 0.3460 - acc: 0.8480 - val_loss: 0.1944 - val_acc: 0.9404\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1265: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/4\n",
            "4671/4671 [==============================] - 68s 15ms/step - loss: 0.2378 - acc: 0.9186 - val_loss: 0.1569 - val_acc: 0.9481\n",
            "Epoch 3/4\n",
            "4671/4671 [==============================] - 69s 15ms/step - loss: 0.2036 - acc: 0.9287 - val_loss: 0.1696 - val_acc: 0.9481\n",
            "Epoch 4/4\n",
            "4671/4671 [==============================] - 69s 15ms/step - loss: 0.1855 - acc: 0.9371 - val_loss: 0.1682 - val_acc: 0.9462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6toyi3H7gIt",
        "colab_type": "text"
      },
      "source": [
        "검증을 하여 정확도가 얼마나 되는지 확인합니다. 약 90% 정도의 성능을 보입니다.  \n",
        "학습된 내용을 텐서보드가 아니더라도 간단하게 볼 수 있도록 그래프를 그립니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_efm_bRqb3G",
        "colab_type": "code",
        "outputId": "c0cb5b87-3041-4c59-9102-3bd6610b6ea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "evaluate = model.evaluate(data.x_test, data.y_test)\n",
        "print(f'loss: {evaluate[0]}, acc: {evaluate[1]}')\n",
        "\n",
        "plt.plot(history.history['acc'], label='accuracy')\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_acc'], label='val_accuracy')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "577/577 [==============================] - 1s 871us/step\n",
            "loss: 0.24198248460759736, acc: 0.9064124783362218\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3GO5ecy7wY3",
        "colab_type": "text"
      },
      "source": [
        "5번에 걸쳐 사용자가 직접 입력해 모델의 성능을 확인합니다.  \n",
        "꽤나 학습이 잘 된 것 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJQRI5qFCokn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "9d0b48d9-2419-4d8e-ac99-a2e3713a9b8b"
      },
      "source": [
        "for i in range(5):\n",
        "    text = input('테스트할 채팅: ')\n",
        "    encoding = encode(text)\n",
        "    if len(encoding) > maxlen:\n",
        "        nplist = np.array(encoding[:maxlen])\n",
        "    else:\n",
        "        # nplist = np.zeros(maxlen)\n",
        "        # for i in range()\n",
        "        encoding = [0] * (maxlen - len(encoding)) + encoding\n",
        "        nplist = np.array(encoding)\n",
        "    d = nplist.reshape((1, maxlen))\n",
        "    print('제재대상일 확률: ' + str(model.predict(d)[0]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "테스트할 채팅: 아 tlqkfㅋㅋㅋㅋ\n",
            "제재대상일 확률: [0.07562654]\n",
            "테스트할 채팅: 음 내가 병신이었네\n",
            "제재대상일 확률: [0.13213903]\n",
            "테스트할 채팅: 아 병신새꺄\n",
            "제재대상일 확률: [0.9062643]\n",
            "테스트할 채팅: 이건 좀 에반데\n",
            "제재대상일 확률: [0.01606259]\n",
            "테스트할 채팅: 시발ㅋ\n",
            "제재대상일 확률: [0.9697169]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4XIIeTv74NF",
        "colab_type": "text"
      },
      "source": [
        "모델의 구조를 png 파일로 시각화하여 저장하고, 현 모델을 .h5 확장자로 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_L6ztujMwt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "\n",
        "\n",
        "plot_model(model, show_shapes=True, to_file=base_url + 'model.png')\n",
        "model.save(base_url + 'model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}